import type { Backend, BackendTensor, DType } from "../types";
import {
  abs,
  add,
  arange,
  argmax,
  argmin,
  contiguous,
  div,
  eq,
  exp,
  expand,
  full,
  gather,
  ge,
  gelu,
  gt,
  isfinite,
  le,
  log,
  lt,
  matmul,
  max,
  mean,
  mul,
  narrow,
  narrowBackward,
  ne,
  neg,
  permute,
  relu,
  reshape,
  scatterAdd,
  sigmoid,
  silu,
  sqrt,
  stridedScatterAdd,
  stridedScatterCopy,
  sub,
  sum,
  tanh,
  tensorFromArray,
  transpose,
  tril,
  triu,
  where,
} from "./numeric";

export type { Shape, StridedScatterOptions } from "./numeric";
export {
  abs,
  add,
  arange,
  argmax,
  argmin,
  contiguous,
  div,
  eq,
  exp,
  expand,
  gather,
  ge,
  gelu,
  gt,
  isfinite,
  le,
  log,
  lt,
  matmul,
  max,
  mean,
  mul,
  narrow,
  narrowBackward,
  ne,
  neg,
  permute,
  relu,
  reshape,
  scatterAdd,
  sigmoid,
  silu,
  sqrt,
  stridedScatterAdd,
  stridedScatterCopy,
  sub,
  sum,
  tanh,
  Tensor,
  tensorFromArray,
  transpose,
  tril,
  triu,
  where,
} from "./numeric";

function read(tensor: Tensor): Promise<number[]> {
  return Promise.resolve(tensor.toArray());
}

/**
 * Cast tensor to a different dtype.
 * CPU backend operates on f64 numbers internally, so this is a no-op.
 * Returns the same tensor unchanged.
 */
function cast(a: BackendTensor, _dtype: DType): BackendTensor {
  // CPU backend always uses JavaScript numbers (f64), so casting is a no-op
  return a;
}

export const cpuBackend: Backend = {
  name: "cpu",
  ops: {
    tensorFromArray,
    full,
    arange,
    add,
    sub,
    div,
    mul,
    matmul,
    sqrt,
    relu,
    exp,
    log,
    neg,
    abs,
    tanh,
    sigmoid,
    gelu,
    silu,
    isfinite,
    gather,
    scatterAdd,
    sum,
    max,
    mean,
    argmax,
    argmin,
    gt,
    lt,
    ge,
    le,
    eq,
    ne,
    expand,
    reshape,
    transpose,
    permute,
    narrow,
    narrowBackward,
    contiguous,
    cast,
    where,
    tril,
    triu,
    stridedScatterCopy,
    stridedScatterAdd,
    read,
  },
};
